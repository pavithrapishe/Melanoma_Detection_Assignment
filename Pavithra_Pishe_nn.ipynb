{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavithrapishe/Melanoma_Detection_Assignment/blob/master/Pavithra_Pishe_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem statement: To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
      ],
      "metadata": {
        "id": "Jhzv9nm0N4kL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "id": "5m2NEz9pJ_qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## importing necessary libraries\n",
        "\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import BatchNormalization\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "AyRR3UYAKhfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## If you are using the data by mounting the google drive, use the following :\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "metadata": {
        "id": "heoW6sagOm4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining the path for train and test images\n",
        "\n",
        "data_dir_train = pathlib.Path(\"/content/gdrive/MyDrive/Colab Notebooks/Skin_cancer_assignment_CNN/Train\")\n",
        "data_dir_test = pathlib.Path('/content/gdrive/MyDrive/Colab Notebooks/Skin_cancer_assignment_CNN/Test')"
      ],
      "metadata": {
        "id": "soHzW4_-Mqvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
        "print(image_count_train)\n",
        "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
        "print(image_count_test)"
      ],
      "metadata": {
        "id": "MsL5QzTsNQth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load using keras.preprocessing\n",
        "####Let's load these images off disk using the helpful image_dataset_from_directory utility.\n",
        "\n",
        "##Create a dataset\n",
        "####Define some parameters for the loader:"
      ],
      "metadata": {
        "id": "YGEXamxF2gVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create train & validation dataset from the train directory with a batch size of 32.\n",
        "## Also, make sure you resize your images to 180*180.\n",
        "\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "qySFi3Yj3Dfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use 80% of the images for training, and 20% for validation."
      ],
      "metadata": {
        "id": "QWC2xFIY3Veo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Write your train dataset here\n",
        "## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "o2C5g1QN3aBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Write your validation dataset here\n",
        "## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "AoHGxK1r4M1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List out all the classes of skin cancer and store them in a list.\n",
        "# You can find the class names in the class_names attribute on these datasets.\n",
        "# These correspond to the directory names in alphabetical order.\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "2em3fKtw4TM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the data"
      ],
      "metadata": {
        "id": "C8fwywsT4ozC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a code to visualize one instance of all the nine classes present in the dataset\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "r7EURM2G4ps2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The image_batch is a tensor of the shape (32, 180, 180, 3). This is a batch of 32 images of shape 180x180x3 (the last dimension refers to color channels RGB). The label_batch is a tensor of the shape (32,), these are corresponding labels to the 32 images.\n",
        "\n",
        "Dataset.cache() keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "\n",
        "Dataset.prefetch() overlaps data preprocessing and model execution while training.\n",
        "\n"
      ],
      "metadata": {
        "id": "DEyEuLip5eHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "TsqsSTpK74mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the model\n",
        "#### Todo: Create a CNN model, which can accurately detect 9 classes present in the dataset. Use ```layers.experimental.preprocessing.Rescaling``` to normalize pixel values between (0,1). The RGB channel values are in the `[0, 255]` range. This is not ideal for a neural network. Here, it is good to standardize values to be in the `[0, 1]`"
      ],
      "metadata": {
        "id": "mOT2euMg-9MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a CNN model, which can accurately detect 9 classes present in the dataset.\n",
        "## While building the model, rescale images to normalize pixel values between (0,1).\n",
        "\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "num_classes = 9\n",
        "\n",
        "model = Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "zD5fsbk7_shA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Choose an appropriate optimiser and loss function for model training\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yVDx_H4izWTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## View the summary of all layers\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "rCYtWHKQzZ-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train the model for ~20 epochs\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 32\n",
        "\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  batch_size=batch_size,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "d5tCl54o0gXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing training results"
      ],
      "metadata": {
        "id": "AQzz-pTS0zoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Oj357Yjz3R_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the plots above, the training accuracy is increasing linearly over time, whereas validation accuracy stalls around 60% in the training process. Also, the difference in accuracy between training and validation accuracy is noticeable — a sign of overfitting."
      ],
      "metadata": {
        "id": "WOzsFRuMWHv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(train_ds, verbose=1,)\n",
        "loss_v, accuracy_v = model.evaluate(val_ds, verbose=1)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Validation Accuracy: \",accuracy_v)\n",
        "print(\"Loss: \",loss)\n",
        "print(\"Validation Loss\", loss_v)"
      ],
      "metadata": {
        "id": "6UQRDwXQ3Z2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Findings based on the first base model\n",
        "\n",
        "The model is overfitting because we can also see difference in loss functions in training & test around the 10-11th epoch\n",
        "\n",
        "The accuracy is just around 75-80% because there are enough features to remember the pattern.\n",
        "\n",
        "But again, it's too early to comment on the overfitting & underfitting debate"
      ],
      "metadata": {
        "id": "Kq0sz4lo3zMi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying data augmentation strategies"
      ],
      "metadata": {
        "id": "whdg_FzlZsTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Chose an appropriate data augmentation strategy to resolve underfitting/overfitting\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\",\n",
        "                                                 input_shape=(img_height,\n",
        "                                                              img_width,\n",
        "                                                              3)),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "iCcCDvTzP-49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise Augmented data for one instance of data\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "2g0M7qj4Wlz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrain model with augmented data"
      ],
      "metadata": {
        "id": "-PrD53OlZ3SW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a CNN model, which can accurately detect 9 classes present in the dataset.\n",
        "## While building the model rescale images to normalize pixel values between (0,1).\n",
        "\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "PrR7S6S6afUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Choose an appropriate optimiser and loss function for model training\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4mVb8qc1amcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train the model for ~20 epochs\n",
        "\n",
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "k0EoT5IEarVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Visualise model\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X_Y5MH5Oa4l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Findings from Second Model:\n",
        "\n",
        "There is no improvement in accuracy but we can definitely see the overfitting problem has solved due to data augmentation\n",
        "\n",
        "We can increase the epochs to increase the accuracy so it's too early for judgement"
      ],
      "metadata": {
        "id": "8dCOEb30bK75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find the distribution of classes in the training dataset.\n",
        "#### **Context:** Many times real life datasets can have class imbalance, one class can have proportionately higher number of samples compared to the others. Class imbalance can have a detrimental effect on the final model quality. Hence as a sanity check it becomes important to check what is the distribution of classes in the data."
      ],
      "metadata": {
        "id": "D23HTfvKbrys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Examine the current class distribution in the training dataset\n",
        "\n",
        "path_list=[]\n",
        "lesion_list=[]\n",
        "for i in class_names:\n",
        "\n",
        "    for j in data_dir_train.glob(i+'/*.jpg'):\n",
        "        path_list.append(str(j))\n",
        "        lesion_list.append(i)\n",
        "dataframe_dict_original = dict(zip(path_list, lesion_list))\n",
        "original_df = pd.DataFrame(list(dataframe_dict_original.items()),columns = ['Path','Label'])\n",
        "original_df"
      ],
      "metadata": {
        "id": "YYcg_jo8cSPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_dict_original = dict(zip(path_list, lesion_list))\n",
        "original_df = pd.DataFrame(list(dataframe_dict_original.items()),columns = ['Path','Label'])\n",
        "original_df"
      ],
      "metadata": {
        "id": "PrVY12oKfVln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count=[]\n",
        "for i in class_names:\n",
        "    count.append(len(list(data_dir_train.glob(i+'/*.jpg'))))\n",
        "plt.figure(figsize=(25,10))\n",
        "plt.bar(class_names,count)"
      ],
      "metadata": {
        "id": "UOkOppomfaiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Which class has the least number of samples?\n",
        "\n",
        "\n",
        "> **squamous cell carcinoma** has least number of samples\n",
        "\n",
        "\n",
        "\n",
        "Which classes dominate the data in terms of the proportionate number of samples?\n",
        "\n",
        "\n",
        "> **actinic keratosis** and **dermatofibroma** have proportionate number of classes.\n",
        "**melanoma** and pigmented benign keratosis have proprtionate number of classes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iLQ8kr1df_1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rectify class imbalance\n",
        "\n",
        "You can use a python package known as Augmentor (https://augmentor.readthedocs.io/en/master/) to add more samples across all classes so that none of the classes have very few samples."
      ],
      "metadata": {
        "id": "pyX3bQ-cgNJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Augmentor"
      ],
      "metadata": {
        "id": "FkBldxkcgTx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use Augmentor, the following general procedure is followed:\n",
        "\n",
        "1.   Instantiate a Pipeline object pointing to a directory containing your initial image data set.\n",
        "2.   Define a number of operations to perform on this data set using your Pipeline object.\n",
        "3.    Execute these operations by calling the Pipeline’s sample() method.\n",
        "\n"
      ],
      "metadata": {
        "id": "Sa_OD-q_govD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Rectify class imbalances present in the training dataset with Augmentor library.\n",
        "\n",
        "path_to_training_dataset=\"/content/gdrive/MyDrive/Colab Notebooks/Skin_cancer_assignment_CNN/Train\"\n",
        "import Augmentor\n",
        "for i in class_names:\n",
        "    p = Augmentor.Pipeline(path_to_training_dataset, save_format='jpg')\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse."
      ],
      "metadata": {
        "id": "nG9iKaQ_gtR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Augmentor has stored the augmented images in the output sub-directory of each of the sub-directories of skin cancer types.. Lets take a look at total count of augmented images.\n",
        "\n",
        "data_dir_train1 = pathlib.Path(\"/content/gdrive/MyDrive/Colab Notebooks/Skin_cancer_assignment_CNN/Train/output\")\n",
        "image_count_train1 = len(list(data_dir_train1.glob('*/*.jpg')))\n",
        "print(image_count_train1)"
      ],
      "metadata": {
        "id": "JmWEX4U3hg4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Lets see the distribution of augmented data after adding new images to the original training data.\n",
        "for i in class_names:\n",
        "  for j in data_dir_train1.glob(i+'/*.jpg'):\n",
        "    path_list.append(str(j))\n",
        "    lesion_list.append(i)\n",
        "dataframe_dict_original = dict(zip(path_list, lesion_list))\n",
        "new_df = pd.DataFrame(list(dataframe_dict_original.items()),columns = ['Path','Label'])\n",
        "new_df"
      ],
      "metadata": {
        "id": "_HQqyw_tjOh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['Label'].value_counts()"
      ],
      "metadata": {
        "id": "UmciyLFVj99X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, now we have added 500 images to all the classes to maintain some class balance. We can add more images as we want to improve training process.\n",
        "\n"
      ],
      "metadata": {
        "id": "6RPTsssQkQl6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train the model on the data created using Augmentor\n"
      ],
      "metadata": {
        "id": "rAkLvsGbkWzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "AR4PXKBBkeMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "data_dir_train1=pathlib.Path(\"/content/gdrive/MyDrive/Colab Notebooks/Skin_cancer_assignment_CNN/Train/output\")"
      ],
      "metadata": {
        "id": "-rU4GvnwkhjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count_train1 = len(list(data_dir_train1.glob('*/*.jpg')))\n",
        "print(image_count_train1)"
      ],
      "metadata": {
        "id": "X0PYK5NQlH4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating training dataset"
      ],
      "metadata": {
        "id": "jZr2TK0llLm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir_train1=pathlib.Path(\"/content/gdrive/MyDrive/Colab Notebooks/Skin_cancer_assignment_CNN/Train\")\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train1,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = \"training\",\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "Hfg6VtD3lWhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating validation dataset"
      ],
      "metadata": {
        "id": "coGJm8N5lXs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train1,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'validation',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "CJdLMgEXlj6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a model"
      ],
      "metadata": {
        "id": "J1OPnD2rlmp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a CNN model, which can accurately detect 9 classes present in the dataset.\n",
        "## While building the model, rescale images to normalize pixel values between (0,1).\n",
        "\n",
        "num_classes = 9\n",
        "model = Sequential([\n",
        "                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n",
        "\n",
        "])\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',\n",
        "                 activation ='relu', input_shape = (180, 180, 32)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',\n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same',\n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same',\n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation = \"softmax\"))"
      ],
      "metadata": {
        "id": "JnuSwD0WlxFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Choose an appropriate optimiser and loss function for model training\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ojsoR3vWl0_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train the model for ~30 epochs\n",
        "\n",
        "epochs =30\n",
        "\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")\n"
      ],
      "metadata": {
        "id": "mVIz16D7l838"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Visualise the model\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2sSCwbAkmCDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Accuracy on training data has increased by using Augmentor library\n",
        "\n",
        "- Model is still overfitting\n",
        "\n",
        "- The problem of overfitting can be solved by add more layer,neurons or adding dropout layers.\n",
        "\n",
        "- The Model can be further improved by tuning the hyperparameter"
      ],
      "metadata": {
        "id": "SAosHFjGmu6G"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CYSgVble5CNB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}